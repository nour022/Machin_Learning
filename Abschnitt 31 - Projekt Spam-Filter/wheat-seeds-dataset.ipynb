{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Wheat Seeds Dataset involves the prediction of species given measurements of seeds from different varieties of wheat.\n",
    "\n",
    "# created by Nikolay K. MTK: 673010\n",
    "It is a multiclass (3-class) classification problem. \n",
    "The number of observations for each class is balanced. \n",
    "There are 210 observations with 7 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "Area.\n",
    "Perimeter.\n",
    "Compactness\n",
    "Length of kernel.\n",
    "Width of kernel.\n",
    "Asymmetry coefficient.\n",
    "Length of kernel groove.\n",
    "Class (1, 2, 3).\n",
    "\n",
    "The baseline performance of predicting the most prevalent class is a classification accuracy of approximately 28%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's layout our plan here\n",
    "solution_steps = [\n",
    "    \"1. Getting the data ready\",\n",
    "    \"2. Choose the right estimator/algorithm for our problems\",\n",
    "    \"3. Fit the model/algorithm and use it to make predictions on our data\",\n",
    "    \"4. Evaluating a model\",\n",
    "    \"5. Improve a model\",\n",
    "    \"6. Save and load a trained model\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Length of kernel</th>\n",
       "      <th>Width of kernel</th>\n",
       "      <th>Asymmetry coefficient</th>\n",
       "      <th>Length of kernel groove</th>\n",
       "      <th>Class (1, 2, 3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area  Perimeter  Compactness  Length of kernel  Width of kernel  \\\n",
       "0    15.26      14.84       0.8710             5.763            3.312   \n",
       "1    14.88      14.57       0.8811             5.554            3.333   \n",
       "2    14.29      14.09       0.9050             5.291            3.337   \n",
       "3    13.84      13.94       0.8955             5.324            3.379   \n",
       "4    16.14      14.99       0.9034             5.658            3.562   \n",
       "..     ...        ...          ...               ...              ...   \n",
       "205  12.19      13.20       0.8783             5.137            2.981   \n",
       "206  11.23      12.88       0.8511             5.140            2.795   \n",
       "207  13.20      13.66       0.8883             5.236            3.232   \n",
       "208  11.84      13.21       0.8521             5.175            2.836   \n",
       "209  12.30      13.34       0.8684             5.243            2.974   \n",
       "\n",
       "     Asymmetry coefficient  Length of kernel groove  Class (1, 2, 3)  \n",
       "0                    2.221                    5.220                1  \n",
       "1                    1.018                    4.956                1  \n",
       "2                    2.699                    4.825                1  \n",
       "3                    2.259                    4.805                1  \n",
       "4                    1.355                    5.175                1  \n",
       "..                     ...                      ...              ...  \n",
       "205                  3.631                    4.870                3  \n",
       "206                  4.325                    5.003                3  \n",
       "207                  8.315                    5.056                3  \n",
       "208                  3.598                    5.044                3  \n",
       "209                  5.637                    5.063                3  \n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wheat_seeds_class = pd.read_excel(\"data/seeds.xlsx\")\n",
    "wheat_seeds_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting our data ready to be used with machine learning\n",
    "\n",
    "Split the data into features and lables (usually 'X' and 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Length of kernel</th>\n",
       "      <th>Width of kernel</th>\n",
       "      <th>Asymmetry coefficient</th>\n",
       "      <th>Length of kernel groove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Perimeter  Compactness  Length of kernel  Width of kernel  \\\n",
       "0  15.26      14.84       0.8710             5.763            3.312   \n",
       "1  14.88      14.57       0.8811             5.554            3.333   \n",
       "2  14.29      14.09       0.9050             5.291            3.337   \n",
       "3  13.84      13.94       0.8955             5.324            3.379   \n",
       "4  16.14      14.99       0.9034             5.658            3.562   \n",
       "\n",
       "   Asymmetry coefficient  Length of kernel groove  \n",
       "0                  2.221                    5.220  \n",
       "1                  1.018                    4.956  \n",
       "2                  2.699                    4.825  \n",
       "3                  2.259                    4.805  \n",
       "4                  1.355                    5.175  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features\n",
    "X = wheat_seeds_class.drop(\"Class (1, 2, 3)\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Class (1, 2, 3), dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "y = wheat_seeds_class[\"Class (1, 2, 3)\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((168, 7), (42, 7), (168,), (42,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choose the right estimator/algorithm for our problems\n",
    "\n",
    "* Sklearn refers to machine learning models, algorithms as estimators.\n",
    "* Classification problem - predicting a category ( 1, 2 or 3)\n",
    " * Somethimes we will see clf (short for classifier) used as a classification estimator\n",
    "* 3 class classification problem\n",
    "* This is often referred to as model or clf (short for classifier) or estimator (as in the Scikit-Learn) documentation.\n",
    "\n",
    "* Hyperparameters are like knobs on an oven you can tune to cook your favourite dish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used choosing the right estimator flowchart from the scikit learn page\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Picking a machine learning model for a classification problem\n",
    "Consulting the map and it says to try LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = LinearSVC(dual=False)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    70\n",
       "2    70\n",
       "1    70\n",
       "Name: Class (1, 2, 3), dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wheat_seeds_class[\"Class (1, 2, 3)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Random Forest Classifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest Classifier\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidbit:\n",
    "\n",
    "1. If you have structured data, used ensemble methods\n",
    "2. If you have unstructured data, use deep learning or transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the model/algorithm on our data and use it to make predictions\n",
    "\n",
    "# 3.1 Fitting the model to the data\n",
    "\n",
    "Different names for:\n",
    "\n",
    "* `X` = features, features variables, data\n",
    "* `y` = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the data (training the ML model)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Random Forest Classifier (use the patterns the model has learned)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest model deep dive\n",
    "Link to more info about RFM\n",
    "\n",
    "https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Make predictions using a ML model\n",
    " 2 ways to make predictions:\n",
    "        1. predict()\n",
    "        2. predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Length of kernel</th>\n",
       "      <th>Width of kernel</th>\n",
       "      <th>Asymmetry coefficient</th>\n",
       "      <th>Length of kernel groove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13.16</td>\n",
       "      <td>13.82</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>5.454</td>\n",
       "      <td>2.975</td>\n",
       "      <td>0.8551</td>\n",
       "      <td>5.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>11.27</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>5.088</td>\n",
       "      <td>2.763</td>\n",
       "      <td>4.3090</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>19.51</td>\n",
       "      <td>16.71</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>6.366</td>\n",
       "      <td>3.801</td>\n",
       "      <td>2.9620</td>\n",
       "      <td>6.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>12.76</td>\n",
       "      <td>13.38</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>5.073</td>\n",
       "      <td>3.155</td>\n",
       "      <td>2.8280</td>\n",
       "      <td>4.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>11.42</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>5.008</td>\n",
       "      <td>2.850</td>\n",
       "      <td>2.7000</td>\n",
       "      <td>4.607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area  Perimeter  Compactness  Length of kernel  Width of kernel  \\\n",
       "30   13.16      13.82       0.8662             5.454            2.975   \n",
       "172  11.27      12.97       0.8419             5.088            2.763   \n",
       "84   19.51      16.71       0.8780             6.366            3.801   \n",
       "199  12.76      13.38       0.8964             5.073            3.155   \n",
       "60   11.42      12.86       0.8683             5.008            2.850   \n",
       "\n",
       "     Asymmetry coefficient  Length of kernel groove  \n",
       "30                  0.8551                    5.056  \n",
       "172                 4.3090                    5.000  \n",
       "84                  2.9620                    6.185  \n",
       "199                 2.8280                    4.830  \n",
       "60                  2.7000                    4.607  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 1, 1, 3, 1, 3, 1, 3, 2, 3, 1, 2, 1, 2, 1, 1, 3, 2, 2, 1,\n",
       "       3, 2, 2, 1, 1, 2, 1, 3, 3, 3, 2, 1, 2, 2, 3, 2, 2, 3, 1, 3],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a trained model to make predictions\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 3, 1, 3, 1, 3, 1, 3, 2, 3, 3, 2, 1, 2, 3, 1, 3, 2, 2, 1,\n",
       "       3, 2, 2, 3, 1, 2, 1, 3, 3, 1, 2, 1, 2, 2, 3, 2, 2, 3, 3, 3],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare predictions to truth labels to evaluate the model\n",
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions with `predict_proba()` - use this if someone asks you \"what's the probability your model is assigning to each prediction?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85, 0.  , 0.15],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [0.  , 1.  , 0.  ],\n",
       "       [0.67, 0.  , 0.33],\n",
       "       [0.63, 0.  , 0.37],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  ],\n",
       "       [0.74, 0.26, 0.  ],\n",
       "       [0.48, 0.  , 0.52]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_proba() returns probabilities of a classification label\n",
    "clf.predict_proba(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 1, 1, 3, 1, 3, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's predict() on the same data...\n",
    "clf.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Length of kernel</th>\n",
       "      <th>Width of kernel</th>\n",
       "      <th>Asymmetry coefficient</th>\n",
       "      <th>Length of kernel groove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13.16</td>\n",
       "      <td>13.82</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>5.454</td>\n",
       "      <td>2.975</td>\n",
       "      <td>0.8551</td>\n",
       "      <td>5.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>11.27</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>5.088</td>\n",
       "      <td>2.763</td>\n",
       "      <td>4.3090</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>19.51</td>\n",
       "      <td>16.71</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>6.366</td>\n",
       "      <td>3.801</td>\n",
       "      <td>2.9620</td>\n",
       "      <td>6.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>12.76</td>\n",
       "      <td>13.38</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>5.073</td>\n",
       "      <td>3.155</td>\n",
       "      <td>2.8280</td>\n",
       "      <td>4.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>11.42</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>5.008</td>\n",
       "      <td>2.850</td>\n",
       "      <td>2.7000</td>\n",
       "      <td>4.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>11.19</td>\n",
       "      <td>13.05</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>5.250</td>\n",
       "      <td>2.675</td>\n",
       "      <td>5.8130</td>\n",
       "      <td>5.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>13.80</td>\n",
       "      <td>14.04</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>5.376</td>\n",
       "      <td>3.155</td>\n",
       "      <td>1.5600</td>\n",
       "      <td>4.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>5.240</td>\n",
       "      <td>2.909</td>\n",
       "      <td>4.8570</td>\n",
       "      <td>5.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.44</td>\n",
       "      <td>15.25</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.884</td>\n",
       "      <td>3.505</td>\n",
       "      <td>1.9690</td>\n",
       "      <td>5.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>12.79</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>5.224</td>\n",
       "      <td>3.054</td>\n",
       "      <td>5.4830</td>\n",
       "      <td>4.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area  Perimeter  Compactness  Length of kernel  Width of kernel  \\\n",
       "30   13.16      13.82       0.8662             5.454            2.975   \n",
       "172  11.27      12.97       0.8419             5.088            2.763   \n",
       "84   19.51      16.71       0.8780             6.366            3.801   \n",
       "199  12.76      13.38       0.8964             5.073            3.155   \n",
       "60   11.42      12.86       0.8683             5.008            2.850   \n",
       "155  11.19      13.05       0.8253             5.250            2.675   \n",
       "45   13.80      14.04       0.8794             5.376            3.155   \n",
       "182  12.19      13.36       0.8579             5.240            2.909   \n",
       "9    16.44      15.25       0.8880             5.884            3.505   \n",
       "196  12.79      13.53       0.8786             5.224            3.054   \n",
       "\n",
       "     Asymmetry coefficient  Length of kernel groove  \n",
       "30                  0.8551                    5.056  \n",
       "172                 4.3090                    5.000  \n",
       "84                  2.9620                    6.185  \n",
       "199                 2.8280                    4.830  \n",
       "60                  2.7000                    4.607  \n",
       "155                 5.8130                    5.219  \n",
       "45                  1.5600                    4.961  \n",
       "182                 4.8570                    5.158  \n",
       "9                   1.9690                    5.533  \n",
       "196                 5.4830                    4.958  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating a machine learning model\n",
    "Three ways to evaluate Scikit-Learn models/estimators:\n",
    "\n",
    "1. Estimator's built-in score() method\n",
    "2. The scoring parameter\n",
    "3. Problem-specific metric functions\n",
    "\n",
    "    You can read more about these here: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import cross validation score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Evaluating using the score parameter\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9047619 , 0.92857143, 0.97619048, 0.97619048, 0.69047619])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85714286, 0.95238095, 0.95238095, 0.9047619 , 1.        ,\n",
       "       0.95238095, 1.        , 0.95238095, 0.66666667, 0.85714286])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n",
      "[[10  0  1]\n",
      " [ 0 14  0]\n",
      " [ 5  0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.91      0.77        11\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.86      0.87      0.86        42\n",
      "weighted avg       0.88      0.86      0.86        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Different classification metrics\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improve through experimentation\n",
    "Two of the main methods to improve a models baseline metrics (the first evaluation metrics you get).\n",
    "\n",
    "From a data perspective asks:\n",
    "\n",
    "* Could we collect more data? In machine learning, more data is generally better, as it gives a model more opportunities to learn patterns.\n",
    "* Could we improve our data? This could mean filling in misisng values or finding a better encoding (turning things into numbers) strategy.\n",
    "\n",
    "From a model perspective asks:\n",
    "\n",
    "* Is there a better model we could use? If you've started out with a simple model, could you use a more complex one? (we saw an example of this when looking at the Scikit-Learn machine learning map, ensemble methods are generally considered more complex models)\n",
    "* Could we improve the current model? If the model you're using performs well straight out of the box, can the hyperparameters be tuned to make it even better?\n",
    "\n",
    "Hyperparameters are like settings on a model you can adjust so some of the ways it uses to find patterns are altered and potentially improved. Adjusting hyperparameters is referred to as hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to find a model's hyperparameters\n",
    "clf = RandomForestClassifier()\n",
    "clf.get_params() # returns a list of adjustable hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9433962264150944\n",
      "0.9622641509433962\n"
     ]
    }
   ],
   "source": [
    "# Example of adjusting hyperparameters by hand\n",
    "\n",
    "# Split data into X & y\n",
    "X = wheat_seeds_class.drop(\"Class (1, 2, 3)\", axis=1) # use all columns except target\n",
    "y = wheat_seeds_class[\"Class (1, 2, 3)\"] # we want to predict y using X\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Instantiate two models with different settings\n",
    "clf_1 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2 = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Fit both models on training data\n",
    "clf_1.fit(X_train, y_train)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate both models on test data and see which is best\n",
    "print(clf_1.score(X_test, y_test))\n",
    "print(clf_2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   1.2s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   1.3s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   1.3s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   1.2s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.5s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.5s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.5s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.5s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.5s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   1.2s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   1.2s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   1.3s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   1.3s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=sqrt, max_depth=20, total=   1.2s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=500, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=30, total=   0.2s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.0s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.0s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.0s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.0s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   1.0s\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   24.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of adjusting hyperparameters computationally (recommended)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define a grid of hyperparameters\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Set n_jobs to -1 to use all cores (NOTE: n_jobs=-1 is broken as of 8 Dec 2019, using n_jobs=1 works)\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=10, # try 10 models total\n",
    "                            cv=5, # 5-fold cross-validation\n",
    "                            verbose=2) # print out results\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train);\n",
    "\n",
    "# Find the best hyperparameters\n",
    "print(rs_clf.best_params_)\n",
    "\n",
    "# Scoring automatically uses the best hyperparameters\n",
    "rs_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and reload your trained model\n",
    "\n",
    "You can save and load a model with pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a model with pickle\n",
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(rs_clf, open(\"rs_random_forest_model_wheat_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a saved pickle model\n",
    "loaded_pickle_model = pickle.load(open(\"rs_random_forest_model_wheat_1.pkl\", \"rb\"))\n",
    "\n",
    "# Evaluate loaded model\n",
    "loaded_pickle_model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
